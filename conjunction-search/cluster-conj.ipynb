{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3032ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import configparser\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspedas.mms as mms\n",
    "from functions_1 import julian\n",
    "from sgp4.api import Satrec\n",
    "import time\n",
    "\n",
    "r_e = 6371.\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../SpTrack-2.ini\")\n",
    "configUsr = config.get(\"configuration\",\"username\")\n",
    "configPwd = config.get(\"configuration\",\"password\")\n",
    "siteCred = {'identity': configUsr, 'password': configPwd}\n",
    "\n",
    "uriBase                = \"https://www.space-track.org\"\n",
    "requestLogin           = \"/ajaxauth/login\"\n",
    "requestCmdAction       = \"/basicspacedata/query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70f16200",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_pickle('../WHISPER/whi_int.pkl')\n",
    "peri_dt_list = (a['dt2'] - a['dt1'])/2 + a['dt1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a232bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tle_get(epoch_start, days_no, launch_dt:str, decay_dt:str, periapsis): \n",
    "    epoch_range = []\n",
    "    for j in range(days_no + 1):\n",
    "        epoch_range.append((epoch_start + timedelta(days=j)).strftime('%Y-%m-%d'))\n",
    "\n",
    "    with requests.Session() as session:\n",
    "\n",
    "        resp = session.post(uriBase + requestLogin, data = siteCred)\n",
    "        if resp.status_code != 200:\n",
    "            raise MyError(resp, \"POST fail on login\")\n",
    "\n",
    "        satIds = []\n",
    "        epoch = []\n",
    "        tle_1 = []\n",
    "        tle_2 = []\n",
    "        \n",
    "        count=1\n",
    "        \n",
    "        for i in range(len(epoch_range)-1):\n",
    "            if count > 10:\n",
    "                print(\"Snoozing for 90 secs for rate limit reasons (max 30/min and 300/hr)...\")\n",
    "                time.sleep(90)\n",
    "                count = 1\n",
    "            \n",
    "            epoch_s = epoch_range[i]\n",
    "            epoch_e = epoch_range[i+1]\n",
    "\n",
    "            requestTLE_1 = \"/class/gp_history/LAUNCH_DATE/<\" + launch_dt + \"/DECAY_DATE/null-val/OBJECT_TYPE/PAYLOAD/PERIAPSIS/<\" + str(periapsis) + \"/EPOCH/\" + epoch_s + \"--\" + epoch_e + \"/predicates/NORAD_CAT_ID,EPOCH,TLE_LINE1,TLE_LINE2/format/json\"\n",
    "            resp = session.get(uriBase + requestCmdAction + requestTLE_1)\n",
    "            if resp.status_code != 200:\n",
    "                print(resp)\n",
    "                raise MyError(resp, \"GET fail on request for satellites\")\n",
    "            \n",
    "            retData = json.loads(resp.text)\n",
    "            for e in retData:\n",
    "                satIds.append(e['NORAD_CAT_ID'])\n",
    "                tle_1.append([e['TLE_LINE1']])\n",
    "                tle_2.append([e['TLE_LINE2']])\n",
    "                epoch.append(e['EPOCH'])\n",
    "            \n",
    "            requestTLE_2 = \"/class/gp_history/LAUNCH_DATE/<\" + launch_dt + \"/DECAY_DATE/>\" + decay_dt + \"/OBJECT_TYPE/PAYLOAD/PERIAPSIS/<\" + str(periapsis) + \"/EPOCH/\" + epoch_s + \"--\" + epoch_e + \"/predicates/NORAD_CAT_ID,EPOCH,TLE_LINE1,TLE_LINE2/format/json\"\n",
    "            resp = session.get(uriBase + requestCmdAction + requestTLE_1)\n",
    "            if resp.status_code != 200:\n",
    "                print(resp)\n",
    "                raise MyError(resp, \"GET fail on request for satellites\")\n",
    "            \n",
    "            retData = json.loads(resp.text)\n",
    "            for e in retData:\n",
    "                satIds.append(e['NORAD_CAT_ID'])\n",
    "                tle_1.append([e['TLE_LINE1']])\n",
    "                tle_2.append([e['TLE_LINE2']])\n",
    "                epoch.append(e['EPOCH'])\n",
    "            \n",
    "            count+=1\n",
    "            \n",
    "    a = [datetime.strptime(i, '%Y-%m-%dT%H:%M:%S.%f') for i in epoch]\n",
    "    tle_df = pd.DataFrame({'id': satIds, 'epoch': a, 'tle_1': tle_1, 'tle_2': tle_2})\n",
    "\n",
    "    session.close()\n",
    "    \n",
    "    return tle_df\n",
    "\n",
    "def find_conj(dt_start, days_no, obs, min_buffer, is_dist_buffer, peri_dt_list):\n",
    "    tle_df = pd.read_pickle('tle_' + str(dt_start.year) + '_' + ('%02d' % dt_start.month) + '.pkl')\n",
    "    \n",
    "    is_mindist_list = []\n",
    "    is_mindist_t = []\n",
    "    is_mindist_id = []\n",
    "    is_mindist_alt = []\n",
    "    \n",
    "    peri_dt_trun = peri_dt_list[peri_dt_list > dt_start][peri_dt_list < (dt_start + timedelta(days=days_no-1))]\n",
    "    \n",
    "    for i in peri_dt_trun:\n",
    "        j_sta = julian(i - timedelta(minutes=min_buffer))[0]\n",
    "        j_end = julian(i + timedelta(minutes=min_buffer))[0]\n",
    "        j_ran = np.arange(j_sta, j_end, 1/86400)[:-1]\n",
    "        \n",
    "        d = [*set(tle_df['id'])] # all sat norads\n",
    "        e = tle_df.set_index('id')\n",
    "        \n",
    "        # observation satellite\n",
    "        obs_e = e.loc[obs]['epoch']\n",
    "        obs_i = np.argmin([abs(j.total_seconds()) for j in (obs_e - i)])\n",
    "        obs_s = e.loc[obs].iloc[obs_i]['tle_1'][0]\n",
    "        obs_t = e.loc[obs].iloc[obs_i]['tle_2'][0]\n",
    "\n",
    "        d.remove(obs)\n",
    "\n",
    "        for j in d:\n",
    "            f = e.loc[j]['epoch']\n",
    "            g = np.argmin([abs(j.total_seconds()) for j in (f - i)])\n",
    "            s = e.loc[j].iloc[g]['tle_1'][0]\n",
    "            t = e.loc[j].iloc[g]['tle_2'][0]\n",
    "\n",
    "            h = Satrec.twoline2rv(s, t).sgp4_array(j_ran, np.zeros(len(j_ran)))[1]\n",
    "            k = Satrec.twoline2rv(obs_s, obs_t).sgp4_array(j_ran, np.zeros(len(j_ran)))[1]     \n",
    "            is_dist = np.sum( (h - k)**2, axis=1 )**0.5\n",
    "\n",
    "            is_mindist = np.min(is_dist)\n",
    "\n",
    "            if is_mindist < is_dist_buffer:\n",
    "                is_mindist_list.append(is_mindist)\n",
    "                sec_diff = int(np.argmin(is_dist) - int(len(j_ran)/2))\n",
    "                is_mindist_t.append(i + timedelta(seconds = sec_diff))\n",
    "                is_mindist_id.append(j)\n",
    "                alt = np.sum(k[np.argmin(is_dist)]**2)**0.5 - r_e\n",
    "                is_mindist_alt.append(alt)\n",
    "#                 print('--', j)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    return is_mindist_id, is_mindist_t, is_mindist_list, is_mindist_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe39b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snoozing for 90 secs for rate limit reasons (max 30/min and 300/hr)...\n",
      "Snoozing for 90 secs for rate limit reasons (max 30/min and 300/hr)...\n",
      "Snoozing for 90 secs for rate limit reasons (max 30/min and 300/hr)...\n",
      "CPU times: total: 6.7 s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tle_get(datetime(2011,12,1), 31, '2011-12-01', '2012-01-01', 1500).to_pickle('tle_2011_12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae52e55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 53s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "is_id, is_dt, is_dist, is_alt = find_conj(datetime(2011,12,1), 3, str(26464), 10, 500, peri_dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e809ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': is_id, 'time': is_dt, 'dist_km': is_dist, 'alt_km': is_alt}).to_pickle('2011_12_c2_conj.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "353cd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pd.read_pickle('2011_07_c2_conj.pkl')\n",
    "c2 = pd.read_pickle('2011_08_c2_conj.pkl')\n",
    "c3 = pd.read_pickle('2011_09_c2_conj.pkl')\n",
    "c4 = pd.read_pickle('2011_10_c2_conj.pkl')\n",
    "c5 = pd.read_pickle('2011_11_c2_conj.pkl')\n",
    "c6 = pd.read_pickle('2011_12_c2_conj.pkl')\n",
    "\n",
    "pd.concat([c1, c2, c3, c4, c5, c6]).sort_values(by='time').reset_index(drop=True).to_pickle('all_conj_list.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spedas]",
   "language": "python",
   "name": "conda-env-spedas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
